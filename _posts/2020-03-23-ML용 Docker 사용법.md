---
title: "ML용 Docker 사용법"
date: 2020-03-23 15:13:00 +0900
category: dev
layout: post
tags:
  - dev
  - ml
  - docker
---

## 문제

Linux에서 Docker image를 사용한 것 까지는 좋았으나 MNIST 예제를 실행할 때마다 다시 필요한 다운로드 받는 것이 불편했습니다.
호스트 머신에서 같은 작업을 수행한다면 `$HOME/.keras/datasets` 아래에 `mnist.npz`가 저장되어
추후 호출에서는 새로 다운로드 받지 않고 재사용 될 수 있을 테지만,
호스트의 IDE에서 작업하면서 일시적으로 실행되고 사라지는 Docker container에서 그런 상태를 유지하는 것을 신경쓰는 것은 상당히 귀찮은 문제였습니다.
이 문제는 단순히 데이터셋 뿐만이 아니라 추가로 필요한 Python 등의 패키지를 설치한 경우에도 반복될 수 있는 문제입니다.

## 해결

현재 제 디렉토리 구조는 아래와 같습니다.

```
/path/to/project
|-- workspace
|   `-- main.py
`-- run.sh
```

`run.sh`라는 셸 스크립트의 내용은 아래와 같습니다.

```sh
#!/bin/zsh

SCRIPT=`realpath $0`
SCRIPTPATH=`dirname $SCRIPT`

docker run \
  --rm \
  -v "$SCRIPTPATH/workspace:/workspace" \
  -v "$SCRIPTPATH/keras-cache:/root/.keras" \
  -w "/workspace" \
  --gpus 1 \
  tensorflow/tensorflow:latest-gpu-py3 \
  $@
```

위 스크립트는 `./run.sh python main.py` 처럼 실행합니다.
그렇게 하면 Tensorflow가 다 세팅되어 있는 Docker image로부터 `workspace/main.py`가 실행됩니다.

`keras.mnist.load_data()`에 의해서 다운로드된 데이터는 `/root/.keras`에 저장되므로
미리 볼륨으로 바인드 한 `/path/to/proejct/keras-cache`라는 디렉토리에 저장됩니다.
추후에 같은 스크립트로 재실행되면 이미 데이터가 있으므로 다시 다운로드 받지 않을 것입니다.
기존 데이터셋을 삭제할 필요가 있다면 `/path/to/proejct/keras-cache` 디렉토리를 삭제하면 됩니다.

앞으로 필요하다면 pip의 패키지 다운로드 경로 등을 볼륨으로 추가해서 비슷하게 캐시 디렉토리로 사용할 수 있겠습니다.
이를테면 `-v "$SCRIPTPATH/pip-cache:/root/.pip"` 와 같은 옵션을 추가하면 되겠습니다.
